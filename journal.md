# Journal

Thursday 28/09/2022
- Explored how Napari works and its plugins, really just looked at the CellPose integration plugin. Still need to workout how to correct the predictions.
- Had a meeting with Ivor, Helfrid and Ryan for 1 hour where we talked about the features Ryan was collecting on cells, Ivor explained we should explore VAEs to get more features, I talked about my Napari exploration and the 2009 surface curvature histogram paper that Helfrid said was a good start, I proposed to do a Napari presenation to Helfrid's lab and Ivor said I have to make a sketch of what my dissertation will look like.
- I started the GitHub project and started setting up the project with the correct requirements, taking them from the cell-SCT project.
- I need to make a plan of what I want to achieve in the next two weeks for this project.

Monday 03/10/2022
- I ran into some issues while trying to install napari and run it on the Windows Chichester lab computers, but now it is installed and running and I documented how to do it and avoid the issues I had and how I solved them on the "setup.md" file in this project.
- I followed the tutorial from Napari to create a very basic Napari plugin and then how to do it with cookiecutter (which creates a template for you) and I documented one issue I had (not having installed git before installing cookiecutter with pip) and its solution in the "plugin_creation.md" file in this project.

Tuesday 04/10/2022
- I quickly setup Napari on a new Windows computer and made a little correction the the "quick setup" commands, adding the command that pip installs the missing "imageio_ffmpeg" package.
- I read Ivor's email on some thoughts and guidance on the group meetings he will be hosting for his group of 3rd year projects (which I am apart of). I read [this blog on training neural networks](http://karpathy.github.io/2019/04/25/recipe/) that he recommended in his email.
- I sent a ticket to the IT department (because Luke Igerson is sick these days) about getting GlobalProtect installed on every computer.
- I started looking at the available Napari plugins and will start evaluating some of them, with a note inside of this project that keeps track of my review. This will probably be when GlobalProtect will be installed so I can do a quick check with some Omero data of how they work. I will probably spend a few hours testing a few of them.
- Importantly, I need to make a Napari plugin for tomorrow that just measures the size of cells (or their mask from CellPose2 really) that I can show to Ivor and Helfrid to show what I've learned about Napari and how I will be using it. I also need to write a quick document that shows what my objectives will be for this project.

Wednesday 05/10/2022
- Today I played with Napari and trying to create a plugin. I uploaded the plugin I currently have to this GitHub project. The progress has mostly been disabling other widgets. I am trying to find the correct variables to be able to access the different layers in Napari from the plugin as that would let me access the mask generated by CellPose and start doing some tracking. I will be developing this tracking in a separate project, so without Napari, and then reintroducing it to Napari as it is too annoying having to restart it each time (even though it is fast, I need a faster response to my code). 
- I had a meeting with Ivor and Ryan, Helfrid was still stick. Most of the meeting was Ryan talking about soft labelling and Ivor giving advice. He also showed his VAE and Ivor gave some advice on improving it, especially on the loss function used (Ryan was using Binary Cross Entropy loss but since it is a categorical labelling (multi-class) Ivor was recommending Categorial Cross Entropy Loss). I just talked about my progress with discovering Napari, trying to build a plugin and promising a working demo plugin by next Wednesday.
- Ivor reminded me that I have to make a document that shows my core objectives for this project. I am thinking that it will be Napari tracking plugins (maybe only one plugin with the various tracking parts being the widgets) for the size, shape and labelling intensity and there will be an extra part on classifying. For now, I am focusing on being able to build a plugin and then I will do one or two tracking features that I will include in the plugin and evaluate them, then I will go back to the classification that will also be included in the plugin, and then will go back to develop more tracking features that Helfrid's lab's cell biologists may need.
- I will also need to work on the Napari demo for Helfrid's lab and also work on the interim report soon.

Monday 10/10/2022
- Lots of progress: I was able to add some very basic tracking features to a Napari plugin such as counting pixels in the mask (from a selected layer in a drop down menu) which can give some basic info on the size (in pixels) of cells (grouped or individually).
- I spent a lot of time trying to implement the ToolTip from various links that I found online (https://github.com/napari/napari/pull/2658) and I failed. I did learn some stuff about Napari in the process and also that ToolTip can be activated from the preferences and is the data from the status bar in the bottom left of the GUI but I don't understand how to customise it (as in put my own data in the status bar) and make the tooltip appear when the mouse hovers over the cell.
- With the failed ToolTip implementation, I am now working on creating my own. I feel like I can learn a lot doing this about creating Napari plugins. I think this will be the last thing I implement to show Helfrid and Ivor that I can make Napari plugins and can finally move on from software engineering stuff to machine learning stuff (ie implementing machine learning tracking (first making it work) and packaging trainable general models in a Napari plugin). It has to work through a QWidget not a magic widget as the mouse event listeners don't work in the magic widgets (I'm not sure why, probably a scope issue). So I need to find the coordinates of the mouse (done), then see if they correspond to a cell in the numpy array as the mouse coordinates indicate a pixel which is in the numpy array which, if it has a number other than 0, is a cell, and then display that information in a little self dissapearing pop up that I don't want to be a window but just a little text box next to the mouse. Otherwise it can be displayed in a text box with the widget buttons.
- I added my notes which includes ideas to add in this demo plugin in the project. It's called "steps in first Napari plugin". I also added a TIF image and its cellpose mask in the "Example_imgs" folder that I just created in this project to be used when working with this plugin.

Tuesday 11/10/2022
- Another full day's work but I was able to implement the tooltip! Honestly, I learned a lot about Napari and how it works, definetely not all though.
- What is left for the demo Napari plugin is for me to add the basic tracking that I had done in the "magic widget" and add it to the Qwidget as info on the side bar and some in the tooltip. I also want to add the measurement of the intensity of the marker, it would be cool to just be able to click into two points and it would create a square and return (printed probably) the average intensity in the marker, or just in the cell mask. This reminds me that I had other ideas to play with the cell mask such as singling out a cell using its mask. Anything seems possible right now.
- I am following Ian Mackie's advice of doing a little bit everyday on the 3rd year project by doing a lot everyday.

Wednesday 12/10/2022
- Continued working on the demo Napari plugin. Added some label information reading that can be viewed on the right hand side of the Napari window when hovering over a label. Also added creating a new layer which is just the labelled cell (and its surroundings as it takes for the crop coordinates the mouse coordinates) when double clicking on its mask.
- Worked a little bit on the project proposal.
- Had the weekly Wednesday meeting. I talked about my project, the project propsal I have to give back soon, the upcoming interim report, my plan (first work on cell classification, then tracking), my demo Napari plugin and how my exploration there is done for now, and Ivor gave some recommendations about just using the Omero images I can download for now as fighting with ITS is not the priority (since they haven't answered my emails about getting Omero installed in Chichester labs and apparently are swarmed right now).

Thursday 13/10/2022
- I finished and sent the first version of the project proposal to Ivor and Helfrid.
- I made the presentation (once again adapted from the JRA presenation I had to make for Ivor's PhD group) for friday morning's meeting.

Friday 14/10/2022
- We had the group meeting on Friday morning (Ivor, Mae, Ekin, Mihaela, Sergey and me). We all presented which took 1h50 (from 9 to 10:50) and we all asked questions about each others projects as Ivor gave some light feedback and questioning.

Wednesday 19/10/2022
- Made a file to connect to Omero and download the images locally from a plate ID. I downloaded the images from plate id 812 (the one that I used for the JRA) in Richmond and uploaded them to my OneDrive.
- Ivor gave some feedback monday on Slack on my project proposal and said that I should actually do the tracking before the classification as otherwise I will be doing the same as Ryan, and the tracking can actually help the classification. I agreed.
- At the meeting I caught Helfrid up on what I was doing and we discussed the new plan for the project that starts with tracking, Helfrid told me he wanted to see the demo Napari plugin next Monday at 11AM (we set the meeting together) so I want to develop it a little further, maybe add a layer creation or the start of the matching algorithm (but very basic, like just match from the centroids) on a series of micrographs.
- At the meeting Ivor recommended that, to save resources and because they are so similar in the features they look at (probably), just one CNN should segment, classify and track the cells. Therefore, I started working after the meeting on making a U-Net just to segment the cells for now, its in the u_net_exploration project on my GitHub, I made that project public. I got the inspiration to make the CNN a U-Net as that is what CellPose uses. It does not work yet!
- As soon as the meeting ended I just worked on trying to make a U-Net.

Monday 24/10/2022
- Worked on the Napari demo plugin to make the 'single out the cell by double clicking on the mask' actually work and a centroid calculator that also creates a 'points' layer that just shows the centroids of all of the cells.
- Showed the demo Napari plugin to Helfrid and he was happy. He told me more about how he would like the PCNA to be tracked over time to see if we can get some information there about the cell cycle phases. He also presented me to some members of his lab such as Ron. Also there is no Wednesday meeting as Ivor is not here and I met with Helfrid today, I should probably tell Ryan.
- I worked on the PCNA measurement python file which for now only reads the images, singles out the cells and gets their centroids. I need it to get all the images and their mask, get all of their individual cells singled out and then with their centroids do a distance comparison to match up the cells and measure their PCNA (average pixel intensity) and map the change over the 180 images.

Tuesday 25/10/2022
- Worked on the 'read_PCNA' python file to match the cells by coordinate. Right now, it goes up to finding pairs of cells that match between images. So it's not bad, just that because of something that I have just realized about the data that I will explain on the next point, we're getting weird results. But for now, it's able to take a series of images, create masks of them with CellPose, use those masks to single out the cells, get the centroids of the cells, match cells between two images according to the closest centroids, match the pairs of cells according to the matching coordinates between images.
- What I found out about the data, when I downloaded plate 812, is that plate 812 is one big image of a plate of cells that has been cut up into many bits so that it's not just one massive image. Basically, in the 180 TIF images I have, they are all pieces of a puzzle to make one single image. They are not time sequential images like I thought they were. I thought that each image in that plate was of the same cells but at different times: I was wrong, they are just pictures of differents parts of the plate. That means that I cannot do any sequential analysis since the images are not sequential i.e. they are not pictures taken at different points in time of the same cells. Therefore, I need to go back to Richmond and download the pictures taken of the plate at a later time (I'm guessing in a time of minutes or hours). That may not exist: maybe only one picture of the plate was taken and that's it. Since Helfrid's lab studies the cell cycle, I'm sure that there are pictures of the same cells taken at different time, and if plate 812 does not have that, I'll need to ask him for that data.
- My end goal with this part of the project is to be able to match the cells up at different points in time and be able to label them (with the ground truth data method that was used for the CNN during the JRA (basically using metric data from the 4 channels)) and then measuring the change in expression of the markers in the cells and see if those show a pattern with their cell cycle phase. I am hoping for that data to be indicative of a pattern that can be used to classify them. Otherwise it will be a cool thing to implement in the Napari tracking plugin. Furthermore, with the cell matching algorithm, I can also show how much a cell moves and have some cool gifs of individual cells (maybe just plotting their centroids) of them moving. Nice tracking data overall.
- After getting the data tomorrow and seeing if this works, I should also move back to the U-Net soon.

Wednesday 26/10/2022
- I found out today that GlobalProtect was added on the Chichester PCs (at least the one I am randomly using today), since the 18th of October.
- While exploring the plate 812 on Omero to find which parts were sequential (or if it was at all), I found that the pictures of the cells were taken very closely in time (less than a minute) and that the Z-axis (usually used for time) was of size 1x1 for each picture, and that the pictures don't even look sequential (the cells don't match from field to field). Therefore, I concluded that they were not sequential. I did learn about the difference between plates and wells thansk to [this link](https://docs.openmicroscopy.org/ome-model/5.5.7/developers/screen-plate-well.html). I told Helfrid and he told me to use plate ID 449 which has sequential images of cells and are marked with mCherry (which I belive is a PCNA marker just like ALEXA555).
- I tried downloading the data of plate ID 449 from the same computer in the Chichester lab but was unable to as the connection kept failing. I made a Python file called 'omero_download' that should connect, but it does not because of an SSL handshake error. My solution is the following: I'll go to Richmond tomorrow morning and download the data from plate ID 449 locally from there.
- My plan right now is to get some interesting sequential tracking data (just matching the cells, measuring their change in PCNA, measuring their change in size) to show Helfrid that it is progressing. If I can do that by tomorrow that would be great, and then I will continue on the U-Net.